{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO:The purpose of this model is to analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. The accuracy must be above 0.75.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data to start model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersdf = pd.read_csv('users_behavior.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#familiarize yourself with the data\n",
    "\n",
    "usersdf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'is_ultra': 0\n"
     ]
    }
   ],
   "source": [
    "#find missing data\n",
    "missing_is_ultra = usersdf['is_ultra'].isnull().sum()\n",
    "print(f\"Number of missing values in 'is_ultra': {missing_is_ultra}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#find missing data in entire df\n",
    "\n",
    "missing_values = usersdf.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statiscal data for behavior\n",
    "\n",
    "usersdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'is_ultra': 0\n"
     ]
    }
   ],
   "source": [
    "#find missing data\n",
    "missing_is_ultra = usersdf['is_ultra'].isnull().sum()\n",
    "print(f\"Number of missing values in 'is_ultra': {missing_is_ultra}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#find missing data in entire df\n",
    "\n",
    "missing_values = usersdf.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Splitting features and target variable\n",
    "X = usersdf.drop('is_ultra', axis=1)  # Features\n",
    "y = usersdf['is_ultra']  # Target\n",
    "\n",
    "# First split: Train (75%) and Temp (25%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=12345)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: Temp (25%) into Validation (50% of Temp) and Test (50% of Temp)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 2410\n",
      "Validation Set Size: 402\n",
      "Test Set Size: 402\n"
     ]
    }
   ],
   "source": [
    "# Display the sizes of each split\n",
    "print(\"Training Set Size:\", len(X_train))\n",
    "print(\"Validation Set Size:\", len(X_val))\n",
    "print(\"Test Set Size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=12345, solver='liblinear', max_iter=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = log_reg.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7661691542288557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy1 = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Accuracy:\", accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionary\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    accuracy= accuracy_score(y_val, y_val_pred)\n",
    "  \n",
    "    return {\"Accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest\n",
    "rf_params = {'n_estimators': [50, 100, 200],\n",
    "             'max_depth': [5, 10, None],\n",
    "             'min_samples_split': [2, 5, 10]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=12345), rf_params, cv=3, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "results['Random Forest'] = evaluate_model(rf_grid.best_estimator_, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest: {rf_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': {'Accuracy': 0.8109452736318408}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Accuracy  0.8109452736318408\n",
    "# Logistic Regression Accuracy: 0.7761194029850746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best models on the test set\n",
    "final_results = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest\n",
    "final_model = RandomForestClassifier(max_depth=10, min_samples_split=5, n_estimators=50)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "results['Random Forest'] = evaluate_model(rf_grid.best_estimator_, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best models on the test set\n",
    "final_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.7985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random Forest\n",
    "final_results['Random Forest'] = evaluate_model(rf_grid.best_estimator_, X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Display Final Results on Test Set\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "for model_name, metrics in final_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We see our test results are slightly different from the training model.Our Logistic regression model is gicing us an accuracy of .7438 while our Random Forest is giving us a accuracy of 0.7985.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set performance\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set performance\n",
    "y_val_pred = log_reg.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7469\n",
      "Validation Accuracy: 0.7761\n",
      "Test Accuracy: 0.7438\n"
     ]
    }
   ],
   "source": [
    "# Test set performance\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "if train_accuracy - test_accuracy > 0.1:\n",
    "    print(\"⚠️ Warning: Possible overfitting detected! The model performs much better on training data than test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our sanity check passed with the accuracies being inside of 10% from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check for the Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7469\n",
      "Validation Accuracy: 0.8109\n",
      "Test Accuracy: 0.7985\n"
     ]
    }
   ],
   "source": [
    "# Validation set performance\n",
    "y_val_pred = rf_grid.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Test set performance\n",
    "y_test_pred = rf_grid.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "if train_accuracy - test_accuracy > 0.1:\n",
    "    print(\"⚠️ Warning: Possible overfitting detected! The model performs much better on training data than test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest model passes the sanity check with the difference in validation and test being under 10%. I recommend using the Random forest as it has a higher percentage of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:Model Performance:The model achieved a training accuracy of 75%, a validation accuracy of 81%, and a test accuracy of 79%.The model achieved a training accuracy of 75%, a validation accuracy of 81%.The model’s test performance is comparable to the validation performance, suggesting that it generalizes well to unseen data. It seems like overfitting is not an issue. Taking that into consideration I would deploy this model to help phone plan users.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
